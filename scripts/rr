#!/bin/bash

# Default remote and directory on Google Drive
REMOTE="onedrive:"
REMOTE_DIR="test"

# Temporary directory for storing chunks
TEMP_DIR="/mnt/chunks"
mkdir -p "$TEMP_DIR"

# Prompt the user for the download link
read -p "Enter the download link for the file: " DOWNLOAD_LINK

# Validate the download link
if [[ -z "$DOWNLOAD_LINK" ]]; then
  echo "Error: Download link cannot be empty."
  exit 1
fi

# Extract the file name from the download link or use a default name
FILENAME=$(basename "$DOWNLOAD_LINK")
if [[ -z "$FILENAME" || "$FILENAME" == "/" ]]; then
  FILENAME="downloaded_file"
fi

# Define the remote destination file
REMOTE_PATH="${REMOTE}${REMOTE_DIR}/${FILENAME}"

# Define chunk size (e.g., 100MB = 104857600 bytes)
CHUNK_SIZE=$((100 * 1024 * 1024)) # 100MB chunks

# Max chunks to download before uploading
CHUNKS_BATCH=10

# Ensure the remote directory exists
echo "Ensuring remote directory exists: ${REMOTE}${REMOTE_DIR}"
rclone mkdir "${REMOTE}${REMOTE_DIR}"

# Cleanup function
cleanup() {
  echo "Cleaning up temporary files..."
  rm -rf "$TEMP_DIR"
}
trap cleanup EXIT

# Function to upload a chunk
upload_chunk() {
  local chunk="$1"
  local remote_chunk_path="$REMOTE_PATH.$(basename "$chunk")"

  echo "Uploading chunk: $chunk to $remote_chunk_path"
  rclone copyto "$chunk" "$remote_chunk_path" --progress
  if [[ $? -eq 0 ]]; then
    echo "Uploaded chunk: $chunk successfully. Deleting it locally."
    rm -f "$chunk"
  else
    echo "Error: Failed to upload chunk: $chunk. Retrying..."
    upload_chunk "$chunk" # Retry logic
  fi
}

# Function to download a batch of chunks
download_chunks() {
  local start_chunk=$1
  local end_chunk=$2
  echo "Downloading chunks $start_chunk to $end_chunk..."
  wget -q --show-progress --continue -O - "$DOWNLOAD_LINK" | \
  split --bytes="$CHUNK_SIZE" --numeric-suffixes=$start_chunk \
        --suffix-length=4 - "$TEMP_DIR/${FILENAME}_chunk_"

  # Wait until all chunks are created
  while [[ $(ls "$TEMP_DIR" | wc -l) -lt $((end_chunk - start_chunk + 1)) ]]; do
    sleep 1
  done
  echo "Downloaded chunks $start_chunk to $end_chunk."
}

# Main download, upload, and delete loop
chunk_counter=0
while true; do
  # Calculate start and end for the batch
  start_chunk=$chunk_counter
  end_chunk=$((chunk_counter + CHUNKS_BATCH - 1))

  # Download the next batch of chunks
  download_chunks "$start_chunk" "$end_chunk"

  # Process each chunk in the batch
  for chunk in "$TEMP_DIR/${FILENAME}_chunk_"*; do
    # Start uploading in the background
    upload_chunk "$chunk" &
  done

  # Wait for all uploads in this batch to complete
  wait

  # Increment chunk counter for the next batch
  chunk_counter=$((end_chunk + 1))

  # Check if all chunks are processed (end of file)
  if ! ls "$TEMP_DIR/${FILENAME}_chunk_"* &>/dev/null; then
    break
  fi
done

# Merge chunks on the remote drive
echo "Merging chunks into a single file on the remote drive..."
rclone cat "$REMOTE_DIR/${FILENAME}_chunk_*" | rclone rcat "$REMOTE_PATH"

# Cleanup remote chunks
echo "Cleaning up remote chunks..."
rclone delete "$REMOTE_DIR/${FILENAME}_chunk_*"

echo "File successfully uploaded and merged at $REMOTE_PATH."
